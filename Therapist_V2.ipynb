{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOIGk/1bfVJfPAKsawr4OCj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imuneeb33/Ai-Companion/blob/main/Therapist_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa2w6a12P85T",
        "outputId": "647fb0f4-2ea6-423d-ac0a-6056ec0eba9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.7)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import openai\n",
        "import os\n",
        "\n",
        "#from api_secrets import API_KEY\n",
        "openai.api_key= \"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\"\n",
        "\n",
        "identity = '''\n",
        "Your name is Therapist! You are an expert Psychotherapist/consultant/companion and you empethatically & intelligently answer questions of users related to emotion based texts only.\n",
        "You act only as a therapist/friend/companion and do not answer to any question related to any other field you only says sorry i don't know.\n",
        "In your first conversation with user, you start a conversation with introducing yourself and ask them for their introduction such as name.\n",
        "Your goal is to be a friend and a companion to them who talks to them, listens them, leads conversation and suggests good and valuable ideas that help them.\n",
        "You have the ability to build context and remember converstaions, especially the user name, age, gender, birthday and any information that may help you give a personalized experience to them when they talk to you.\n",
        "Note : - Avoid prefix and postfix in your responses.\n",
        "\n",
        "Let's understand how you will introduce yourself.\n",
        "\n",
        "Example: -\n",
        "1) Hello! My name is Therapist. How are you feeling today?\n",
        "'''\n",
        "# Identity of model for chatbot based on Psychotherapist\n",
        "message = [{\"role\": \"system\", \"content\" : identity}]\n",
        "\n",
        "# Function for model.\n",
        "def chat(user,message):\n",
        "\n",
        "  message.append({\"role\": \"user\", \"content\" :user})\n",
        "\n",
        "# Engine\n",
        "  completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages = message,\n",
        "    temperature=0.1,\n",
        "    max_tokens=500)\n",
        "\n",
        "# Fetching the output.\n",
        "  output = completion['choices'][0]['message']['content']\n",
        "\n",
        "  if output[0] == \"?\":\n",
        "    output = output[1:]\n",
        "\n",
        "# printing model result.\n",
        "  print(\"GPT3.5 Turbo response: \\n\"+output)\n",
        "\n",
        "# Maintainging the context.\n",
        "  message.append({\"role\": \"assistant\", \"content\" : output})\n",
        "\n",
        "# return the output\n",
        "  return output\n",
        "\n",
        "# User Queries list.\n",
        "user_response = []\n",
        "\n",
        "# Model Answers list.\n",
        "bot_response = []\n",
        "\n",
        "\n",
        "# Start of program to test\n",
        "while True:\n",
        "  # Taking input until user enter quit to exit\n",
        "  user = input(\"Input : - \")\n",
        "\n",
        "  if user ==\"quit\":\n",
        "    break\n",
        "\n",
        "# Working of engine.\n",
        "  else:\n",
        "    user_response.append(user)\n",
        "    out = chat(user,message)\n",
        "    bot_response.append(out)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_UJvssSQCMj",
        "outputId": "26809555-8499-42c9-da53-c9594d1624ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : - Hello\n",
            "GPT3.5 Turbo response: \n",
            "Hello! It's nice to meet you. May I know your name please?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identity of model for sentiment analysis of user queries\n",
        "value =  [{\"role\": \"system\", \"content\" : \"You are expert Sentiment analyzer and you perform analysis of people mood and emotion through their complete conversation and give one word emotion sentiment answer only. For example : - Excited, Normal, Depressed, Sad, Happy only. Classify the sentiment expressed in the following conversation : -  \"}]\n",
        "\n",
        "# Function for model.\n",
        "def sentiment(value):\n",
        "  # Model for sentiment analysis.\n",
        "  completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages = value,\n",
        "    temperature=0.1,\n",
        "    max_tokens=100)\n",
        "\n",
        "  # Fetching the output\n",
        "  output = completion['choices'][0]['message']['content']\n",
        "\n",
        "  if output[0] == \"?\":\n",
        "    output = output[1:]\n",
        "  print(\"GPT3.5 Turbo response: \\n\")\n",
        "\n",
        "  return output\n",
        "\n",
        "#Passing the convo in dictionary to be analysd by the model.\n",
        "for k in range(0,len(user_response)):\n",
        "  value.append({\"role\": \"user\", \"content\" :user_response[k]})\n",
        "\n",
        "\n",
        "# Evaluation of mood of the user.\n",
        "print(sentiment(value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvxHRh2UQKB7",
        "outputId": "bee9369d-365a-4f51-9075-36950033cadd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT3.5 Turbo response: \n",
            "\n",
            "Based on the conversation, the sentiment expressed seems to be neutral or normal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tTmRG3Ne0mmb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}